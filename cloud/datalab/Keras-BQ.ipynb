{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actualizamos paquetes críticos y listamos todos los instalados en la VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "pip install sklearn --upgrade\n",
    "pip install --upgrade tensorflow\n",
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejemplo 1: llamada a la API de BQ \n",
    "Extraído de los notebooks de muestra de Datalab \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "\n",
    "# Hacemos una query para obtenerlos nacimientos de varones cada año\n",
    "total_births = bq.Query('SELECT CAST(source_year AS string) AS year, COUNT(is_male) AS birth_count FROM `publicdata.samples.natality` GROUP BY year ORDER BY year DESC LIMIT 15')\n",
    "df = total_births.execute(output_options=bq.QueryOutput.dataframe()).result()\n",
    "\n",
    "# Vemos las 10 primeras filas del dataframe\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ploteamos la query\n",
    "ax = df.plot(kind='bar',x='year',title='Total births by year')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Birth count')\n",
    "\n",
    "# Hacemos una query para obtenerlos nacimientos de niños cada día de la semana\n",
    "births_by_weekday = bq.Query('SELECT CAST(wday AS string) AS weekday, SUM(CASE WHEN is_male THEN 1 ELSE 0 END) AS male_births, SUM(CASE WHEN is_male THEN 0 ELSE 1 END) AS female_births FROM `publicdata.samples.natality` WHERE wday IS NOT NULL GROUP BY weekday ORDER BY weekday ASC')\n",
    "df2 = births_by_weekday.execute(output_options=bq.QueryOutput.dataframe()).result()\n",
    "\n",
    "# Ploteamos la query\n",
    "df2 = births_by_weekday.execute(output_options=bq.QueryOutput.dataframe()).result()\n",
    "ax = df2.plot(kind='line',x='weekday',title='Births by weekday')\n",
    "ax.set_xlabel('Weekday')\n",
    "ax.set_ylabel('Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejemplo 2: llamada llamada 'mágica' a BQ\n",
    "Usamos la tabla de BQ de ejemplo con los viajes en taxi en Chicago desde 2013 (105 millones de filas - 36GB)\n",
    "Intentaremos predecir el precio del viaje en taxi en función de las coordenadas donde se recoge y se deja al cliente, la duración y la distancia del viaje\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bq query -n taxi_queries\n",
    "SELECT trip_seconds, trip_miles, pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, fare\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "WHERE trip_miles IS NOT NULL AND\n",
    "      trip_seconds IS NOT NULL AND\n",
    "      pickup_latitude IS NOT NULL AND \n",
    "      pickup_longitude IS NOT NULL AND\n",
    "      dropoff_latitude IS NOT NULL AND\n",
    "      dropoff_longitude IS NOT NULL AND  \n",
    "      fare IS NOT NULL\n",
    "LIMIT 300000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ejecutamos la query\n",
    "df = taxi_queries.execute(output_options=bq.QueryOutput.dataframe()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalización de columnas (normalizamos todo el dataset, por lo que no tenemos que guardar la media ni la desviación)\n",
    "\n",
    "cols_to_norm = ['pickup_latitude','pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "df[cols_to_norm] = df[cols_to_norm].apply(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df.plot(kind='scatter',x='pickup_longitude', y='pickup_latitude', title='Pickup locations')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df.plot(kind='scatter',x='dropoff_longitude', y='dropoff_latitude', title='Dropoff locations')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df['fare'].hist()\n",
    "ax.set_xlabel('Fares')\n",
    "ax.set_ylabel('Number of trips')\n",
    "ax.set_title('Fares histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Veamos tras aplicar algoritmos de reducción de dimensionalidad si los viajes con tarifas más comunes son \"diferentes\" del resto (es decir, si no tenemos que hacer feature engineering)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "df_aux = df.sample(500)\n",
    "\n",
    "# Consideramos tarifas \"normales\" entre $4.8 y $7.5\n",
    "df_aux['normal_fare'] = df_aux['fare'].apply(lambda x: 1 if x >= 4.8 and x <= 7.5  else 0)\n",
    "df_aux.drop('fare', axis=1, inplace=True)\n",
    "\n",
    "# Nos quedamos con la columna de etiquetas\n",
    "y = df_aux.ix[:,-1].values\n",
    "\n",
    "df_aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_aux['normal_fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Construimos un gráfico con los puntos obtenidos al aplicar tsne o PCA\n",
    "def plot_data_2d(X, y, x_lims = None, y_lims = None):\n",
    "  color_map = {0:'red', 1:'blue'}\n",
    "  plt.figure()\n",
    "  for idx, cl in enumerate(np.unique(y)):\n",
    "    plt.scatter(x = X[y==cl,0], \n",
    "                y = X[y==cl,1], \n",
    "                c = color_map[idx], \n",
    "                label = cl)\n",
    "  plt.xlabel('X in t-SNE')\n",
    "  plt.ylabel('Y in t-SNE')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.title('t-SNE visualization of Chicago taxi trips')\n",
    "  if x_lims is not None and y_lims is not None:\n",
    "    plt.xlim(x_lims)\n",
    "    plt.ylim(y_lims)\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Usamos PCA en este caso\n",
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(df_aux)\n",
    "X = pca.transform(df_aux)\n",
    "\n",
    "x_lims = (X[:,0].mean()-1000,X[:,0].mean()+1000)\n",
    "y_lims = (X[:,1].mean()-10,X[:,1].mean()+10)\n",
    "\n",
    "plot_data_2d(X, y, x_lims, y_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creamos una visualización en 2d con el algoritmo t-SNE para ver la diferencia entre viajes con tarifas \"más comunes\" y el resto\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# Scale features to improve the training ability of TSNE.\n",
    "standard_scaler = StandardScaler()\n",
    "df_std = standard_scaler.fit_transform(df_aux)\n",
    "\n",
    "# Compute t-SNE algorithm\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "tsne_2d = tsne.fit_transform(df_std)\n",
    "\n",
    "#Construimos un gráfico con los puntos obtenidos al aplicar tsne\n",
    "plot_data_2d(tsne_2d, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "TEST_SIZE = 0.1\n",
    "VAL_SIZE = 0.1\n",
    "\n",
    "dataset = df.as_matrix()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = ms.train_test_split(dataset[:,:-1], dataset[:,-1], test_size=TEST_SIZE, random_state=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = ms.train_test_split(X_train, Y_train, test_size=VAL_SIZE/TRAIN_SIZE, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow\n",
    "#import tensorflow as tf\n",
    "import sys\n",
    "import tensorflow.contrib.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from tensorflow.contrib.keras import *\n",
    "from tensorflow.contrib.keras.python.keras.regularizers import l1,l2\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential, load_model\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.contrib.keras.python.keras.constraints import max_norm\n",
    "from tensorflow.contrib.keras.python.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.contrib.keras.python.keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "\n",
    "# Disable info warnings from TF\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Volvemos a limitar el resultado de la query\n",
    "LIMIT = 10000\n",
    "\n",
    "# Limitamos los ejemplos de entrenamiento a viajes de menos de 20$\n",
    "\n",
    "mask_train = Y_train < 20\n",
    "mask_val = Y_val < 20\n",
    "mask_test = Y_test < 20\n",
    "\n",
    "\n",
    "X_train = X_train[mask_train]\n",
    "Y_train = Y_train[mask_train]\n",
    "X_val = X_val[mask_val]\n",
    "Y_val = Y_val[mask_val]\n",
    "X_test = X_test[mask_test]\n",
    "Y_test = Y_test[mask_test]\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 500\n",
    "epochs = 100\n",
    "dropout_rate = 0.5\n",
    "\n",
    "TRAIN_LIMIT = int(LIMIT*TRAIN_SIZE)\n",
    "VAL_LIMIT = int(LIMIT*VAL_SIZE)\n",
    "TEST_LIMIT = int(LIMIT*TEST_SIZE)\n",
    "\n",
    "x_train = X_train[:TRAIN_LIMIT]\n",
    "y_train = Y_train[:TRAIN_LIMIT]\n",
    "x_val = X_val[:VAL_LIMIT]\n",
    "y_val = Y_val[:VAL_LIMIT]\n",
    "x_test = X_test[:TEST_LIMIT]\n",
    "y_test = Y_test[:TEST_LIMIT]\n",
    "\n",
    "# Tenemos 6 neuronas de entrada\n",
    "input_dim = dataset.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2,input_shape=(input_dim,), kernel_initializer='he_normal'))\n",
    "#model.add(Dense(3,input_shape=(input_dim,)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=[keras.metrics.mean_absolute_error, keras.metrics.mean_absolute_percentage_error])\n",
    "\n",
    "# Entrenamos el modelo (con verbose 0 apagamos el log y con 1 se muestra con barra de progreso)\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss (mse):', score[0])\n",
    "print('Test mae:', score[1])\n",
    "print('Test mape:', score[2])\n",
    "\n",
    "y_pred = model.predict_proba(x_test, verbose = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PLOT_LIM = 15\n",
    "# Plot para ver como se desvían nuestras prediciones\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test[:LIMIT], y_pred[:LIMIT] )\n",
    "ax.plot([0, PLOT_LIM], [0, PLOT_LIM], 'k--', lw=3)\n",
    "ax.set_xlim([0, PLOT_LIM])\n",
    "ax.set_ylim([0, PLOT_LIM])\n",
    "ax.set_title('Chicago taxi trips prediction')\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(x_test[49:50], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test[49:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abs(y_pred - y_test[50:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
